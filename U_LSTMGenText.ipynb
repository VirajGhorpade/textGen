{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "U_LSTMGenText.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "za0eM7g-bqKK",
        "colab_type": "code",
        "outputId": "1059edcc-4101-481d-b95d-82f05f3f78e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Code to read csv file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 21.9MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 3.2MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 3.0MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 3.5MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 4.0MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 4.5MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 3.4MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 3.4MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 3.4MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 3.4MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 3.4MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NH-MuBvwSKj-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "83510a2a-ba8a-4108-dbce-81d741652c5d"
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lOVBtS3UJs1",
        "colab_type": "code",
        "outputId": "aadccc7b-efc6-46fd-d3cf-9bef9df03b00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        }
      },
      "source": [
        "# Small LSTM Network to Generate Text for Alice in Wonderland\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "# load ascii text and covert to lowercase\n",
        "downloaded = drive.CreateFile({'id':'1q6sTmTtOWxeI_m53aalvrZ0yAp7eXLE2'}) #https://drive.google.com/open?id=1q6sTmTtOWxeI_m53aalvrZ0yAp7eXLE2\n",
        "filename = \"wonderland4.txt\"#\"/content/drive/My Drive/wonderland4.txt\"\n",
        "downloaded.GetContentFile(filename)\n",
        "raw_text = open(filename).read()\n",
        "raw_text = raw_text.lower()\n",
        "splitted_to_print = raw_text.split(' ')\n",
        "for count in range(5):\n",
        "  print(splitted_to_print[count])\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0727 04:08:10.599227 139645337835392 __init__.py:44] file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 36, in autodetect\n",
            "    from google.appengine.api import memcache\n",
            "ModuleNotFoundError: No module named 'google.appengine'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 41, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    'file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth')\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "alice's\n",
            "adventures\n",
            "in\n",
            "wonderland\n",
            "\n",
            "chapter\n",
            "i.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZCIO2jwVsc2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "2920f260-7aec-48e7-f3a7-9fa2cc7f2094"
      },
      "source": [
        "import string\n",
        "# Remove punctuations\n",
        "exclude_punctuations = set(string.punctuation)\n",
        "raw_text = ''.join(ch for ch in raw_text if ch not in exclude_punctuations)\n",
        "splitted_to_print = raw_text.split(' ')\n",
        "for count in range(5):\n",
        "  print(splitted_to_print[count])\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "alices\n",
            "adventures\n",
            "in\n",
            "wonderland\n",
            "\n",
            "chapter\n",
            "i\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co5ga-72toxm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "94f3716a-ccbe-4ab3-d3b1-793b4308ef23"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "# summarize the loaded data\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \", n_chars)\n",
        "print (\"Total Vocab: \", n_vocab)\n",
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\n",
        "  seq_in = raw_text[i:i + seq_length]\n",
        "  seq_out = raw_text[i + seq_length]\n",
        "  \n",
        "  dataX.append([char_to_int[char] for char in seq_in])\n",
        "  dataY.append(char_to_int[seq_out])\n",
        "\n",
        "\n",
        " # padding the sequence, this is usefull at the end data sequence\n",
        "dataX = pad_sequences(dataX, padding='post', maxlen=100)\n",
        "print(dataX)\n",
        "\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \", n_patterns)\n",
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  136036\n",
            "Total Vocab:  28\n",
            "[[ 0  2 13 ... 21 10 19]\n",
            " [ 2 13 10 ... 10 19  6]\n",
            " [13 10  4 ... 19  6  5]\n",
            " ...\n",
            " [20  1  2 ...  1  5  2]\n",
            " [ 1  2 15 ...  5  2 26]\n",
            " [ 2 15  5 ...  2 26 20]]\n",
            "Total Patterns:  135936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XKaJOwtVWm5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "d8b21d41-b813-47bb-a7ba-592bf2b69976"
      },
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# https://machinelearningmastery.com/how-to-reduce-overfitting-with-dropout-regularization-in-keras/\n",
        "# if dropout is given to the input layer, a different dropout mask is applied to each time step within each sample presented to the LSTM.\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), dropout=0.1,return_sequences=True))\n",
        "#This dropout is added between two LSTM layers\n",
        "#adds dropout to 256 outputs and provided as input to the secong LSTM layer\n",
        "model.add(Dropout(0.1))# drop out with 0.1 \n",
        "model.add(LSTM(256))\n",
        "# Remove drop out \n",
        "# model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0727 04:08:25.296041 139645337835392 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0727 04:08:25.332828 139645337835392 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0727 04:08:25.338696 139645337835392 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0727 04:08:25.529798 139645337835392 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0727 04:08:25.541810 139645337835392 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOnZHaiPNh_i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "1d2b23d8-15f8-4b6b-9ffb-9e6400aece25"
      },
      "source": [
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# fit the model\n",
        "model.fit(X, y, epochs=10, batch_size=64)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "135936/135936 [==============================] - 582s 4ms/step - loss: 2.6589\n",
            "Epoch 2/10\n",
            "135936/135936 [==============================] - 580s 4ms/step - loss: 2.2664\n",
            "Epoch 3/10\n",
            "135936/135936 [==============================] - 580s 4ms/step - loss: 2.0613\n",
            "Epoch 4/10\n",
            "135936/135936 [==============================] - 579s 4ms/step - loss: 1.9179\n",
            "Epoch 5/10\n",
            "135936/135936 [==============================] - 579s 4ms/step - loss: 1.7952\n",
            "Epoch 6/10\n",
            "135936/135936 [==============================] - 581s 4ms/step - loss: 1.7110\n",
            "Epoch 7/10\n",
            "135936/135936 [==============================] - 580s 4ms/step - loss: 1.6059\n",
            "Epoch 8/10\n",
            "135936/135936 [==============================] - 580s 4ms/step - loss: 1.5913\n",
            "Epoch 9/10\n",
            "135936/135936 [==============================] - 581s 4ms/step - loss: 1.6574\n",
            "Epoch 10/10\n",
            "135936/135936 [==============================] - 579s 4ms/step - loss: 1.5912\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa2b6941898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVFJRXqDNghx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "15487c06-e805-40d1-e791-6c7adca6896d"
      },
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save(\"A2_LSTM_model_v1.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "\n",
        "from google.colab import files\n",
        "files.download('A2_LSTM_model_v1.h5')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9MWBLFeVGYt",
        "colab_type": "code",
        "outputId": "58423617-9279-42ad-c700-bf0bded00ea2",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# 2nd 20 epochs  => 10+20 = 30\n",
        "\n",
        "from google.colab import files\n",
        "model_new = files.upload()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2111f95b-2a6c-4826-91f3-175ac9650d0c\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-2111f95b-2a6c-4826-91f3-175ac9650d0c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving A2_LSTM_model_v1.h5 to A2_LSTM_model_v1 (1).h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0GCHNkoWIIU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 913
        },
        "outputId": "9f0cbc79-890e-4fe6-e3e2-eacd8f3800c3"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model_new = load_model(\"A2_LSTM_model_v1 (1).h5\")\n",
        "\n",
        "\n",
        "model_new.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# fit the model\n",
        "model_new.fit(X, y, epochs=20, batch_size=64)\n",
        "\n",
        "# Save the trained weights in to .h5 format\n",
        "model_new.save(\"A2_LSTM_model_v2.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "\n",
        "from google.colab import files\n",
        "files.download('A2_LSTM_model_v2.h5')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "135936/135936 [==============================] - 584s 4ms/step - loss: 1.5428\n",
            "Epoch 2/20\n",
            "135936/135936 [==============================] - 577s 4ms/step - loss: 1.5031\n",
            "Epoch 3/20\n",
            "135936/135936 [==============================] - 580s 4ms/step - loss: 1.4654\n",
            "Epoch 4/20\n",
            "135936/135936 [==============================] - 580s 4ms/step - loss: 1.4289\n",
            "Epoch 5/20\n",
            "135936/135936 [==============================] - 580s 4ms/step - loss: 1.4012\n",
            "Epoch 6/20\n",
            "135936/135936 [==============================] - 578s 4ms/step - loss: 1.3685\n",
            "Epoch 7/20\n",
            "135936/135936 [==============================] - 580s 4ms/step - loss: 1.3440\n",
            "Epoch 8/20\n",
            "135936/135936 [==============================] - 583s 4ms/step - loss: 1.3208\n",
            "Epoch 9/20\n",
            "135936/135936 [==============================] - 583s 4ms/step - loss: 1.2983\n",
            "Epoch 10/20\n",
            "135936/135936 [==============================] - 577s 4ms/step - loss: 1.2790\n",
            "Epoch 11/20\n",
            "135936/135936 [==============================] - 578s 4ms/step - loss: 1.2568\n",
            "Epoch 12/20\n",
            "135936/135936 [==============================] - 576s 4ms/step - loss: 1.2407\n",
            "Epoch 13/20\n",
            "135936/135936 [==============================] - 579s 4ms/step - loss: 1.2233\n",
            "Epoch 14/20\n",
            "135936/135936 [==============================] - 578s 4ms/step - loss: 1.2086\n",
            "Epoch 15/20\n",
            "135936/135936 [==============================] - 571s 4ms/step - loss: 1.1947\n",
            "Epoch 16/20\n",
            "135936/135936 [==============================] - 567s 4ms/step - loss: 1.1794\n",
            "Epoch 17/20\n",
            "135936/135936 [==============================] - 568s 4ms/step - loss: 1.1647\n",
            "Epoch 18/20\n",
            "135936/135936 [==============================] - 571s 4ms/step - loss: 1.1539\n",
            "Epoch 19/20\n",
            "135936/135936 [==============================] - 573s 4ms/step - loss: 1.1449\n",
            "Epoch 20/20\n",
            "135936/135936 [==============================] - 585s 4ms/step - loss: 1.1348\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-d2b59638d205>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'A2_LSTM_model_v2.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mdeadline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mdeadline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36m_read_next_input_message\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mavailable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m   \"\"\"\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mipython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m   \u001b[0mstdin_socket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_ipython.py\u001b[0m in \u001b[0;36mget_kernel\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_ipython.py\u001b[0m in \u001b[0;36mget_ipython\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/getipython.py\u001b[0m in \u001b[0;36mget_ipython\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mReturns\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mno\u001b[0m \u001b[0mInteractiveShell\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mregistered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \"\"\"\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteractiveshell\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInteractiveShell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mInteractiveShell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mInteractiveShell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fR8Yt3z49Qs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('A2_LSTM_model_v2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP4ebWxx7BdW",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "bc34d6d0-06f8-47ad-a9e3-38c1d999aa13"
      },
      "source": [
        "# 3rd 5 epochs  => 30+5= 35\n",
        "\n",
        "from google.colab import files\n",
        "model_new = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7b15e955-e94c-42d5-b9c0-a5a468f2a541\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-7b15e955-e94c-42d5-b9c0-a5a468f2a541\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving A2_LSTM_model_v2.h5 to A2_LSTM_model_v2.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIyxG6uCTpbu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "b79b350e-9d6b-4755-9949-433166fbd89f"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model_new3 = load_model(\"A2_LSTM_model_v2.h5\")\n",
        "\n",
        "\n",
        "model_new3.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# fit the model\n",
        "model_new3.fit(X, y, epochs=5, batch_size=64)\n",
        "\n",
        "# Save the trained weights in to .h5 format\n",
        "model_new3.save(\"A2_LSTM_model_v3.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "135936/135936 [==============================] - 570s 4ms/step - loss: 1.1311\n",
            "Epoch 2/5\n",
            "135936/135936 [==============================] - 572s 4ms/step - loss: 1.1155\n",
            "Epoch 3/5\n",
            "135936/135936 [==============================] - 571s 4ms/step - loss: 1.1072\n",
            "Epoch 4/5\n",
            "135936/135936 [==============================] - 569s 4ms/step - loss: 1.1107\n",
            "Epoch 5/5\n",
            "135936/135936 [==============================] - 566s 4ms/step - loss: 1.0890\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9jKf9vj3Ui2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('A2_LSTM_model_v3.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBeG1o-O7cSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 4th 5 epochs  => 35+5= 40\n",
        "\n",
        "from google.colab import files\n",
        "model_new = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSFjXpTb-b9E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "a842602f-a15d-4eb8-be75-d951130de712"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model_new4 = load_model(\"A2_LSTM_model_v3.h5\")\n",
        "\n",
        "\n",
        "model_new4.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# fit the model\n",
        "model_new4.fit(X, y, epochs=5, batch_size=64)\n",
        "\n",
        "# Save the trained weights in to .h5 format\n",
        "model_new4.save(\"A2_LSTM_model_v4.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "135936/135936 [==============================] - 574s 4ms/step - loss: 1.0836\n",
            "Epoch 2/5\n",
            "135936/135936 [==============================] - 573s 4ms/step - loss: 1.0761\n",
            "Epoch 3/5\n",
            "135936/135936 [==============================] - 573s 4ms/step - loss: 1.0651\n",
            "Epoch 4/5\n",
            "135936/135936 [==============================] - 572s 4ms/step - loss: 1.0677\n",
            "Epoch 5/5\n",
            "135936/135936 [==============================] - 571s 4ms/step - loss: 1.0621\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo0FqQ4L-mr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('A2_LSTM_model_v4.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPWu6_iUSgAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 5th 5 epochs  => 40+5= 45\n",
        "\n",
        "from google.colab import files\n",
        "model_new = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Tr_4tjISryq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "1f34fb0c-af04-44d3-fec4-ecd79e08463f"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model_new5 = load_model(\"A2_LSTM_model_v4.h5\")\n",
        "\n",
        "\n",
        "model_new5.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# fit the model\n",
        "model_new5.fit(X, y, epochs=5, batch_size=64)\n",
        "\n",
        "# Save the trained weights in to .h5 format\n",
        "model_new5.save(\"A2_LSTM_model_v5.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "135936/135936 [==============================] - 576s 4ms/step - loss: 1.0579\n",
            "Epoch 2/5\n",
            "135936/135936 [==============================] - 570s 4ms/step - loss: 1.0531\n",
            "Epoch 3/5\n",
            "135936/135936 [==============================] - 569s 4ms/step - loss: 1.0411\n",
            "Epoch 4/5\n",
            "135936/135936 [==============================] - 569s 4ms/step - loss: 1.0411\n",
            "Epoch 5/5\n",
            "135936/135936 [==============================] - 569s 4ms/step - loss: 1.0375\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dO2SUCS9Ssvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('A2_LSTM_model_v5.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-WdYGb7cUup",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 6th 5 epochs  => 45+5= 50\n",
        "\n",
        "from google.colab import files\n",
        "model_new = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vY6m8Q_ecbba",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "f98c7f62-4493-4a97-822a-4a5cbf5c3155"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model_new6 = load_model(\"A2_LSTM_model_v5.h5\")\n",
        "\n",
        "\n",
        "model_new6.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# fit the model\n",
        "model_new6.fit(X, y, epochs=5, batch_size=64)\n",
        "\n",
        "# Save the trained weights in to .h5 format\n",
        "model_new6.save(\"A2_LSTM_model_v6.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "135936/135936 [==============================] - 578s 4ms/step - loss: 1.0359\n",
            "Epoch 2/5\n",
            "135936/135936 [==============================] - 580s 4ms/step - loss: 1.0295\n",
            "Epoch 3/5\n",
            "135936/135936 [==============================] - 574s 4ms/step - loss: 1.0259\n",
            "Epoch 4/5\n",
            "135936/135936 [==============================] - 574s 4ms/step - loss: 1.0216\n",
            "Epoch 5/5\n",
            "135936/135936 [==============================] - 574s 4ms/step - loss: 1.0220\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wznr5odpcbg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('A2_LSTM_model_v6.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmfZPP1Qt0q_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 7th 5 epochs  => 50+5= 55\n",
        "\n",
        "from google.colab import files\n",
        "model_new = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T8C5Bt6t53U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "34efe463-71df-45f1-ac13-d2168bcca28e"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model_new7 = load_model(\"A2_LSTM_model_v6.h5\")\n",
        "\n",
        "\n",
        "model_new7.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# fit the model\n",
        "model_new7.fit(X, y, epochs=5, batch_size=64)\n",
        "\n",
        "# Save the trained weights in to .h5 format\n",
        "model_new7.save(\"A2_LSTM_model_v7.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "135936/135936 [==============================] - 575s 4ms/step - loss: 1.0238\n",
            "Epoch 2/5\n",
            "135936/135936 [==============================] - 571s 4ms/step - loss: 1.0165\n",
            "Epoch 3/5\n",
            "135936/135936 [==============================] - 571s 4ms/step - loss: 1.0108\n",
            "Epoch 4/5\n",
            "135936/135936 [==============================] - 574s 4ms/step - loss: 1.0046\n",
            "Epoch 5/5\n",
            "135936/135936 [==============================] - 574s 4ms/step - loss: 1.0098\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OINRkp_6t6B8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('A2_LSTM_model_v7.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks6gtdTxLfUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 8th 5 epochs  => 55+5= 60\n",
        "\n",
        "from google.colab import files\n",
        "model_new = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj1mSPN3Lff8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "b8dae56e-6e81-4506-8d9c-80345803977b"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model_new8 = load_model(\"A2_LSTM_model_v7.h5\")\n",
        "\n",
        "\n",
        "model_new8.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# fit the model\n",
        "model_new8.fit(X, y, epochs=5, batch_size=64)\n",
        "\n",
        "# Save the trained weights in to .h5 format\n",
        "model_new8.save(\"A2_LSTM_model_v8.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "135936/135936 [==============================] - 581s 4ms/step - loss: 1.0121\n",
            "Epoch 2/5\n",
            "135936/135936 [==============================] - 578s 4ms/step - loss: 1.0022\n",
            "Epoch 3/5\n",
            "135936/135936 [==============================] - 580s 4ms/step - loss: 1.0065\n",
            "Epoch 4/5\n",
            "135936/135936 [==============================] - 577s 4ms/step - loss: 1.0018\n",
            "Epoch 5/5\n",
            "135936/135936 [==============================] - 577s 4ms/step - loss: 0.9968\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w6OaEuvLfrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('A2_LSTM_model_v8.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYXLojjgbpWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 9th 5 epochs  => 60+5= 65\n",
        "\n",
        "from google.colab import files\n",
        "model_new = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEArK9GzcQ0m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "a4b31a57-4737-4c5b-8028-365a15514875"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model_new9 = load_model(\"A2_LSTM_model_v8.h5\")\n",
        "\n",
        "\n",
        "model_new9.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# fit the model\n",
        "model_new9.fit(X, y, epochs=5, batch_size=64)\n",
        "\n",
        "# Save the trained weights in to .h5 format\n",
        "model_new9.save(\"A2_LSTM_model_v9.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "135936/135936 [==============================] - 579s 4ms/step - loss: 1.1096\n",
            "Epoch 2/5\n",
            "135936/135936 [==============================] - 575s 4ms/step - loss: 2.8571\n",
            "Epoch 3/5\n",
            "135936/135936 [==============================] - 573s 4ms/step - loss: 2.7351\n",
            "Epoch 4/5\n",
            "135936/135936 [==============================] - 574s 4ms/step - loss: 2.6479\n",
            "Epoch 5/5\n",
            "135936/135936 [==============================] - 574s 4ms/step - loss: 2.6041\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkFhjVIZcREL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('A2_LSTM_model_v9.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8Oows6rnw-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 10th 5 epochs  => 65+5= 70\n",
        "\n",
        "from google.colab import files\n",
        "model_new = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2QHAgjSn0y7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "eea15c4e-fc70-404f-af20-d4e4af83080c"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model_new10 = load_model(\"A2_LSTM_model_v9.h5\")\n",
        "\n",
        "\n",
        "model_new10.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# fit the model\n",
        "model_new10.fit(X, y, epochs=5, batch_size=64)\n",
        "\n",
        "# Save the trained weights in to .h5 format\n",
        "model_new10.save(\"A2_LSTM_model_v10.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "135936/135936 [==============================] - 584s 4ms/step - loss: 2.5805\n",
            "Epoch 2/5\n",
            "135936/135936 [==============================] - 576s 4ms/step - loss: 2.5570\n",
            "Epoch 3/5\n",
            "135936/135936 [==============================] - 576s 4ms/step - loss: 2.5344\n",
            "Epoch 4/5\n",
            "135936/135936 [==============================] - 575s 4ms/step - loss: 2.5160\n",
            "Epoch 5/5\n",
            "135936/135936 [==============================] - 576s 4ms/step - loss: 2.4977\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiMLx6WFn0-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('A2_LSTM_model_v10.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCiEXIegpBPe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 11th 5 epochs  => 70+5= 75\n",
        "\n",
        "from google.colab import files\n",
        "model_new = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTalJUrtIukj",
        "colab_type": "text"
      },
      "source": [
        "https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/\n",
        "\n",
        "### After 60epochs loss starts to increase, \n",
        "\n",
        "### tried with:\n",
        "\n",
        "### adam with decay-  no much difference\n",
        "\n",
        "### SGD - is showing good reduction in loss\n",
        "\n",
        "### Note: Loaded the last best model weights (A2_LSTM_model_v8.h5)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1POVu-y6Mw4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "159483a2-5543-44b9-905c-a61068d6dce4"
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras import optimizers\n",
        "\n",
        "model_new11 = load_model(\"A2_LSTM_model_v8.h5\")\n",
        "\n",
        "#adam = keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-6, amsgrad=False)\n",
        "\n",
        "model_new11.compile(loss='categorical_crossentropy', optimizer='SGD')\n",
        "# fit the model\n",
        "model_new11.fit(X, y, epochs=5, batch_size=64)\n",
        "\n",
        "# Save the trained weights in to .h5 format\n",
        "model_new11.save(\"A2_LSTM_model_v11.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "135936/135936 [==============================] - 582s 4ms/step - loss: 0.8937\n",
            "Epoch 2/5\n",
            "135936/135936 [==============================] - 572s 4ms/step - loss: 0.8520\n",
            "Epoch 3/5\n",
            "135936/135936 [==============================] - 572s 4ms/step - loss: 0.8340\n",
            "Epoch 4/5\n",
            "135936/135936 [==============================] - 571s 4ms/step - loss: 0.8194\n",
            "Epoch 5/5\n",
            "135936/135936 [==============================] - 576s 4ms/step - loss: 0.8072\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnXmCo3O6M6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('A2_LSTM_model_v11.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYimbwdL7I8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 12th 5 epochs  => 75+5= 80\n",
        "\n",
        "from google.colab import files\n",
        "model_new = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnOJ8_9JC_lZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "181cbe8d-afb9-4542-e8ee-b007fc51066d"
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras import optimizers\n",
        "\n",
        "model_new12 = load_model(\"A2_LSTM_model_v11.h5\")\n",
        "\n",
        "model_new12.compile(loss='categorical_crossentropy', optimizer='SGD')\n",
        "# fit the model\n",
        "model_new12.fit(X, y, epochs=5, batch_size=64)\n",
        "\n",
        "# Save the trained weights in to .h5 format\n",
        "model_new12.save(\"A2_LSTM_model_v12.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "135936/135936 [==============================] - 585s 4ms/step - loss: 0.7991\n",
            "Epoch 2/5\n",
            "135936/135936 [==============================] - 573s 4ms/step - loss: 0.7909\n",
            "Epoch 3/5\n",
            "135936/135936 [==============================] - 574s 4ms/step - loss: 0.7867\n",
            "Epoch 4/5\n",
            "135936/135936 [==============================] - 573s 4ms/step - loss: 0.7838\n",
            "Epoch 5/5\n",
            "135936/135936 [==============================] - 573s 4ms/step - loss: 0.7772\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t5OGvwrUM-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('A2_LSTM_model_v12.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "at8wUK-LbkxJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "e95b43dd-9888-4777-8d73-02dabad0d438"
      },
      "source": [
        "import sys\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print (\"Seed:\")\n",
        "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# generate characters\n",
        "for i in range(1000):\n",
        "\tx1 = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx1 = x1 / float(n_vocab)\n",
        "\tprediction = model_new12.predict(x1, verbose=0)\n",
        "  \n",
        "\tindex = numpy.argmax(prediction)\n",
        "  print (index)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\t#pattern.append(index)\n",
        "\t#pattern = pattern[1:len(pattern)]\n",
        "  #pattern = np.concatenate((a, pattern[1:len(pattern)))\n",
        "print (\"\\nDone.\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-50-ee27cd22da07>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    print (index)\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK9PWiqonivt",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c8e74731-cb42-463d-f77c-0fc6108f55c6"
      },
      "source": [
        "from google.colab import files\n",
        "model_new = files.upload()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c3a51249-9ede-4602-860c-d86b754f7565\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-c3a51249-9ede-4602-860c-d86b754f7565\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving A2_LSTM_model_v12.h5 to A2_LSTM_model_v12.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m0F2oJXf5sK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "cb005a4b-bab2-48d2-a7b3-0c7377423ed2"
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "\n",
        "model_new12 = load_model(\"A2_LSTM_model_v12.h5\")\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)+1)\n",
        "pattern = dataX[start]\n",
        "#pattern=pattern[:-1]\n",
        "#print(pattern)\n",
        "\n",
        "#print \"Seed:\"\n",
        "#print \"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\"\n",
        "# generate characters\n",
        "for i in range(1000):\n",
        "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "   # x = numpy.reshape(x, (1,-1,1)\n",
        "    #print(x.shape)\n",
        "    x = (x / float(n_vocab))\n",
        "    #print(n_vocab)\n",
        "    #print(x.shape)\n",
        "    prediction = model_new12.predict(x, verbose=0)\n",
        "    index = numpy.argmax(prediction)\n",
        "    result = int_to_char[index]\n",
        "    seq_in = [int_to_char[value] for value in pattern]\n",
        "    sys.stdout.write(result)\n",
        "    #print(index)\n",
        "    index= numpy.reshape(index, (1,))\n",
        "    pattern=np.append(pattern,index)\n",
        "    #print(pattern.shape)\n",
        "    #print(pattern)\n",
        "    #pattern.append(index)\n",
        "    pattern = pattern[1:len(pattern)]\n",
        "    #print(pattern.shape)\n",
        "print(\"\\nDone.\")"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dr ie wakd tome severled to tuam slatying ano rne of the werlem of tuch sleasut soatuicrdupee when tuope tound yould you froe if hav the setoee tound her tet and as ie sayher teadi tayherlng uuroishnascling anice\n",
            "\n",
            "it ill swt oote tpat the tain as eurious anice teparked all tound the tat onlert in tuiet tirple taid to toeain soeake rne stam oo toease what stozes nowe his pinen inghing hirself vhe rigeon but the wanksho inttantly tuembling to listed turp anice temark and a loek turtle what iis sueciedertable in toeaseddlew the fod of the whe hanl what a lomept said toeayed once orte tiade atoinping the waller in an imm delng\n",
            "fet a little whree of tound tode her tister back tourdesath chande ovthing heeg\n",
            "\n",
            "hird her anivier separke alice waid turping tound tound tound yould you frol said the cork tueer ins tueer tolebody to the whintle tound at sugslly what i ligh at iu msgstiog all tound the tat oot as inpatpe tattage what a dodo afain rerpie\n",
            "\n",
            "tolshinavsed toalisf to be anl dane dooe the h\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ix7ODCOVmhR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}